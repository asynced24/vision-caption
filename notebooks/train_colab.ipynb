{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vision-Caption Projector Training\n",
        "\n",
        "This notebook trains the projector on COCO captions.\n",
        "\n",
        "Setup checklist:\n",
        "- Enable GPU\n",
        "- Enable Internet (Kaggle)\n",
        "- If you're on Kaggle, add the dataset `awsaf49/coco-2017-dataset`\n",
        "\n",
        "Run cells in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Clone and install\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "if not os.path.isdir(\"vision-caption\"):\n",
        "    subprocess.run(\n",
        "        [\"git\", \"clone\", \"https://github.com/asynced24/vision-caption.git\"],\n",
        "        check=True,\n",
        "    )\n",
        "\n",
        "os.chdir(\"vision-caption\")\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\", \"-q\"], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pycocotools\", \"-q\"], check=True)\n",
        "print(\"Setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Get COCO dataset\n",
        "# - Kaggle: uses /kaggle/input/coco-2017-dataset/coco2017\n",
        "# - Colab: uses Kaggle API if kaggle.json exists, otherwise direct download\n",
        "from pathlib import Path\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "IMAGES_DIR = None\n",
        "ANNOTATIONS_FILE = None\n",
        "\n",
        "\n",
        "def _find_coco_paths(root: Path) -> tuple[str | None, str | None]:\n",
        "    images = None\n",
        "    annotations = None\n",
        "\n",
        "    img_candidates = list(root.glob(\"**/train2017\"))\n",
        "    if img_candidates:\n",
        "        images = str(img_candidates[0])\n",
        "\n",
        "    ann_candidates = list(root.glob(\"**/captions_train2017.json\"))\n",
        "    if ann_candidates:\n",
        "        annotations = str(ann_candidates[0])\n",
        "\n",
        "    return images, annotations\n",
        "\n",
        "\n",
        "def _validate_paths(images: str | None, annotations: str | None) -> tuple[str | None, str | None]:\n",
        "    if images and not os.path.isdir(images):\n",
        "        images = None\n",
        "    if annotations and not os.path.isfile(annotations):\n",
        "        annotations = None\n",
        "    return images, annotations\n",
        "\n",
        "\n",
        "is_kaggle = os.path.isdir(\"/kaggle/input\") or bool(os.environ.get(\"KAGGLE_URL_BASE\"))\n",
        "if is_kaggle:\n",
        "    images = \"/kaggle/input/coco-2017-dataset/coco2017/train2017\"\n",
        "    annotations = \"/kaggle/input/coco-2017-dataset/coco2017/annotations/captions_train2017.json\"\n",
        "    IMAGES_DIR, ANNOTATIONS_FILE = _validate_paths(images, annotations)\n",
        "\n",
        "    if IMAGES_DIR is None or ANNOTATIONS_FILE is None:\n",
        "        raise RuntimeError(\n",
        "            \"COCO not found under /kaggle/input. Add awsaf49/coco-2017-dataset and re-run Step 2.\"\n",
        "        )\n",
        "\n",
        "if IMAGES_DIR is None or ANNOTATIONS_FILE is None:\n",
        "    kaggle_dir = Path.home() / \".kaggle\"\n",
        "    kaggle_json = kaggle_dir / \"kaggle.json\"\n",
        "\n",
        "    if kaggle_json.exists():\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"kaggle\", \"-q\"], check=True)\n",
        "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "        api = KaggleApi()\n",
        "        api.authenticate()\n",
        "\n",
        "        dataset_slug = \"awsaf49/coco-2017-dataset\"\n",
        "        out_dir = Path(\"coco_data\")\n",
        "        out_dir.mkdir(exist_ok=True)\n",
        "        api.dataset_download_files(dataset_slug, path=str(out_dir), unzip=True)\n",
        "\n",
        "        IMAGES_DIR, ANNOTATIONS_FILE = _validate_paths(*_find_coco_paths(out_dir))\n",
        "\n",
        "if IMAGES_DIR is None or ANNOTATIONS_FILE is None:\n",
        "    data_dir = Path(\"coco_data\")\n",
        "    data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    train_zip = data_dir / \"train2017.zip\"\n",
        "    ann_zip = data_dir / \"annotations_trainval2017.zip\"\n",
        "\n",
        "    if not (data_dir / \"train2017\").exists():\n",
        "        print(\"Downloading train2017 images...\")\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"wget\",\n",
        "                \"--progress=bar:force:noscroll\",\n",
        "                \"-O\",\n",
        "                str(train_zip),\n",
        "                \"http://images.cocodataset.org/zips/train2017.zip\",\n",
        "            ],\n",
        "            check=True,\n",
        "        )\n",
        "        subprocess.run([\"unzip\", \"-q\", str(train_zip), \"-d\", str(data_dir)], check=True)\n",
        "        train_zip.unlink(missing_ok=True)\n",
        "\n",
        "    if not (data_dir / \"annotations\").exists():\n",
        "        print(\"Downloading annotations...\")\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"wget\",\n",
        "                \"--progress=bar:force:noscroll\",\n",
        "                \"-O\",\n",
        "                str(ann_zip),\n",
        "                \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\",\n",
        "            ],\n",
        "            check=True,\n",
        "        )\n",
        "        subprocess.run([\"unzip\", \"-q\", str(ann_zip), \"-d\", str(data_dir)], check=True)\n",
        "        ann_zip.unlink(missing_ok=True)\n",
        "\n",
        "    IMAGES_DIR, ANNOTATIONS_FILE = _validate_paths(\n",
        "        str(data_dir / \"train2017\"),\n",
        "        str(data_dir / \"annotations\" / \"captions_train2017.json\"),\n",
        "    )\n",
        "\n",
        "print(\"IMAGES_DIR:\", IMAGES_DIR)\n",
        "print(\"ANNOTATIONS_FILE:\", ANNOTATIONS_FILE)\n",
        "print(\"Dataset ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Train projector\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "if not IMAGES_DIR or not ANNOTATIONS_FILE:\n",
        "    raise RuntimeError(\"IMAGES_DIR/ANNOTATIONS_FILE not set. Run Step 2 first.\")\n",
        "\n",
        "subprocess.run(\n",
        "    [\n",
        "        sys.executable,\n",
        "        \"train.py\",\n",
        "        \"--images-dir\",\n",
        "        IMAGES_DIR,\n",
        "        \"--annotations-file\",\n",
        "        ANNOTATIONS_FILE,\n",
        "        \"--output-dir\",\n",
        "        \"checkpoints\",\n",
        "        \"--epochs\",\n",
        "        \"3\",\n",
        "        \"--batch-size\",\n",
        "        \"32\",\n",
        "        \"--lr\",\n",
        "        \"1e-3\",\n",
        "    ],\n",
        "    check=True,\n",
        ")\n",
        "print(\"Training complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Quick test\n",
        "import os\n",
        "from vision_caption import ModelConfig, load_model\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "projector_path = \"checkpoints/projector_final.pt\"\n",
        "if not os.path.isfile(projector_path):\n",
        "    print(\"No trained projector found yet. Run Step 3 first.\")\n",
        "else:\n",
        "    config = ModelConfig()\n",
        "    config.projector_path = projector_path\n",
        "    model = load_model(config)\n",
        "\n",
        "    url = \"https://images.unsplash.com/photo-1518791841217-8f162f1e1131\"\n",
        "    image = Image.open(BytesIO(requests.get(url).content))\n",
        "\n",
        "    print(\"Caption:\", model.generate(image))\n",
        "    display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Download weights\n",
        "import os\n",
        "\n",
        "projector_path = \"checkpoints/projector_final.pt\"\n",
        "if not os.path.isfile(projector_path):\n",
        "    print(\"No trained projector found yet. Run Step 3 first.\")\n",
        "else:\n",
        "    try:\n",
        "        from google.colab import files\n",
        "\n",
        "        files.download(projector_path)\n",
        "        print(\"Downloaded from Colab\")\n",
        "    except Exception:\n",
        "        print(\"Kaggle: download from the Output tab (checkpoints/projector_final.pt)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
