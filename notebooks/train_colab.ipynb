{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vision-Caption Projector Training\n",
        "\n",
        "This notebook trains the projector on COCO captions.\n",
        "\n",
        "Setup checklist:\n",
        "- Enable GPU\n",
        "- Enable Internet (Kaggle)\n",
        "\n",
        "Run cells in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Clone and install\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "if not os.path.isdir(\"vision-caption\"):\n",
        "    subprocess.run(\n",
        "        [\"git\", \"clone\", \"https://github.com/asynced24/vision-caption.git\"],\n",
        "        check=True,\n",
        "    )\n",
        "\n",
        "os.chdir(\"vision-caption\")\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\", \"-q\"], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pycocotools\", \"-q\"], check=True)\n",
        "print(\"Setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Download COCO dataset (with progress bar)\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "\n",
        "data_dir = Path(\"coco_data\")\n",
        "data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "train_zip = data_dir / \"train2017.zip\"\n",
        "ann_zip = data_dir / \"annotations_trainval2017.zip\"\n",
        "\n",
        "if not (data_dir / \"train2017\").exists():\n",
        "    print(\"Downloading train2017 images...\")\n",
        "    subprocess.run(\n",
        "        [\n",
        "            \"wget\",\n",
        "            \"--progress=bar:force:noscroll\",\n",
        "            \"-O\",\n",
        "            str(train_zip),\n",
        "            \"http://images.cocodataset.org/zips/train2017.zip\",\n",
        "        ],\n",
        "        check=True,\n",
        "    )\n",
        "    subprocess.run([\"unzip\", \"-q\", str(train_zip), \"-d\", str(data_dir)], check=True)\n",
        "    train_zip.unlink(missing_ok=True)\n",
        "\n",
        "if not (data_dir / \"annotations\").exists():\n",
        "    print(\"Downloading annotations...\")\n",
        "    subprocess.run(\n",
        "        [\n",
        "            \"wget\",\n",
        "            \"--progress=bar:force:noscroll\",\n",
        "            \"-O\",\n",
        "            str(ann_zip),\n",
        "            \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\",\n",
        "        ],\n",
        "        check=True,\n",
        "    )\n",
        "    subprocess.run([\"unzip\", \"-q\", str(ann_zip), \"-d\", str(data_dir)], check=True)\n",
        "    ann_zip.unlink(missing_ok=True)\n",
        "\n",
        "print(\"Dataset ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Train projector\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "subprocess.run(\n",
        "    [\n",
        "        sys.executable,\n",
        "        \"train.py\",\n",
        "        \"--images-dir\",\n",
        "        \"coco_data/train2017\",\n",
        "        \"--annotations-file\",\n",
        "        \"coco_data/annotations/captions_train2017.json\",\n",
        "        \"--output-dir\",\n",
        "        \"checkpoints\",\n",
        "        \"--epochs\",\n",
        "        \"3\",\n",
        "        \"--batch-size\",\n",
        "        \"32\",\n",
        "        \"--lr\",\n",
        "        \"1e-3\",\n",
        "    ],\n",
        "    check=True,\n",
        ")\n",
        "print(\"Training complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Quick test\n",
        "from vision_caption import ModelConfig, load_model\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "config = ModelConfig()\n",
        "config.projector_path = \"checkpoints/projector_final.pt\"\n",
        "model = load_model(config)\n",
        "\n",
        "url = \"https://images.unsplash.com/photo-1518791841217-8f162f1e1131\"\n",
        "image = Image.open(BytesIO(requests.get(url).content))\n",
        "\n",
        "print(\"Caption:\", model.generate(image))\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Download weights\n",
        "try:\n",
        "    from google.colab import files\n",
        "\n",
        "    files.download(\"checkpoints/projector_final.pt\")\n",
        "    print(\"Downloaded from Colab\")\n",
        "except Exception:\n",
        "    print(\"Kaggle: download from the Output tab (checkpoints/projector_final.pt)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vision-Caption Projector Training\n",
        "\n",
        "Train the projector on COCO Captions. Works on **Colab** and **Kaggle**.\n",
        "\n",
        "**IMPORTANT:** Enable GPU + Internet first!\n",
        "- **Colab:** Runtime → Change runtime type → T4 GPU\n",
        "- **Kaggle:** Settings → Accelerator → GPU T4 x2 + Internet ON\n",
        "\n",
        "**If Kaggle logs show `Accelerator: None`, GPU is not enabled.**\n",
        "**If `git clone` fails with `Could not resolve host`, Internet is OFF.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Clone and install\n",
        "!git clone https://github.com/asynced24/vision-caption.git\n",
        "%cd vision-caption\n",
        "%pip install -e . -q\n",
        "%pip install pycocotools -q\n",
        "print(\"✓ Setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Download COCO dataset (~19GB)\n",
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path(\"coco_data\")\n",
        "data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "if not (data_dir / \"train2017\").exists():\n",
        "    print(\"Downloading images...\")\n",
        "    !wget -q http://images.cocodataset.org/zips/train2017.zip -P coco_data\n",
        "    !unzip -q coco_data/train2017.zip -d coco_data\n",
        "    !rm coco_data/train2017.zip\n",
        "\n",
        "if not (data_dir / \"annotations\").exists():\n",
        "    print(\"Downloading annotations...\")\n",
        "    !wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P coco_data\n",
        "    !unzip -q coco_data/annotations_trainval2017.zip -d coco_data\n",
        "    !rm coco_data/annotations_trainval2017.zip\n",
        "\n",
        "print(\"✓ Dataset ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Train projector (full COCO)\n",
        "!python train.py --images-dir coco_data/train2017 --annotations-file coco_data/annotations/captions_train2017.json --output-dir checkpoints --epochs 3 --batch-size 32 --lr 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Test trained model\n",
        "from vision_caption import ModelConfig, load_model\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "config = ModelConfig()\n",
        "config.projector_path = \"checkpoints/projector_final.pt\"\n",
        "model = load_model(config)\n",
        "\n",
        "# Test image\n",
        "url = \"https://images.unsplash.com/photo-1518791841217-8f162f1e1131\"\n",
        "image = Image.open(BytesIO(requests.get(url).content))\n",
        "\n",
        "print(f\"Caption: {model.generate(image)}\")\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Download trained weights\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('checkpoints/projector_final.pt')\n",
        "    print(\"✓ Downloaded (Colab)\")\n",
        "except ImportError:\n",
        "    print(\"✓ On Kaggle: Click Output tab → Download projector_final.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
